{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631578947368421"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.datacamp.com/community/blog/scikit-learn-cheat-sheet\n",
    "\n",
    "############# A Basic Example ############\n",
    "from sklearn import neighbors, datasets, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[:, :2], iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Loading The Data ############\n",
    "\n",
    "# Your data needs to be numeric and stored as NumPy arrays or SciPy sparse matrices. Other types that are convertible \n",
    "# to numeric arrays, such as Pandas DataFrame, are also acceptable.\n",
    "\n",
    "import numpy as np\n",
    "X = np.random.random((10,5))\n",
    "y = np.array(['M','M','F','F','M','F','M','M','F','F','F'])\n",
    "X[X < 0.7] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.80717128],\n",
       "       ...,\n",
       "       [1.        , 0.78315957, 0.90930288, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.90866817, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.95497664, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# Preprocessing The Data ############\n",
    "\n",
    "\n",
    "# Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "standardized_X = scaler.transform(X_train)\n",
    "standardized_X_test = scaler.transform(X_test)\n",
    "\n",
    "# Normalization\n",
    "from sklearn.preprocessing import Normalizer\n",
    "scaler = Normalizer().fit(X_train)\n",
    "normalized_X = scaler.transform(X_train)\n",
    "normalized_X_test = scaler.transform(X_test)\n",
    "\n",
    "# Binarization\n",
    "from sklearn.preprocessing import Binarizer\n",
    "binarizer = Binarizer(threshold=0.0).fit(X)\n",
    "binary_X = binarizer.transform(X)\n",
    "\n",
    "# Encoding Categorical Features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(y)\n",
    "\n",
    "# Imputing Missing Values\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values=0, strategy='mean', axis=0)\n",
    "imp.fit_transform(X_train)\n",
    "\n",
    "# Generating Polynomial Features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(5)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Training And Test Data ############\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Create Your Model (Supervised Learning Estimators) ############\n",
    "\n",
    "\n",
    "# Linear Regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression(normalize=True)\n",
    "\n",
    "Support Vector Machines (SVM)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear')\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# KNN\n",
    "\n",
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############# Create Your Model (Unsupervised Learning Estimators) ############\n",
    "\n",
    "\n",
    "# Principal Component Analysis (PCA)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "# K Means\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "k_means = KMeans(n_clusters=3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Model Fitting ############\n",
    "\n",
    "# Supervised learning\n",
    "lr.fit(X, y)\n",
    "knn.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Unsupervised Learning\n",
    "k_means.fit(X_train)\n",
    "pca_model = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Prediction ############\n",
    "\n",
    "\n",
    "# Supervised Estimators\n",
    "y_pred = svc.predict(np.random.random((2,5)))\n",
    "y_pred = lr.predict(X_test)\n",
    "y_pred = knn.predict_proba(X_test)\n",
    "\n",
    "# Unsupervised Estimators\n",
    "y_pred = k_means.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Evaluate Your Model's Performance (Classification Metrics) ############\n",
    "\n",
    "\n",
    "# Accuracy Score\n",
    "knn.score(X_test, y_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############# Evaluate Your Model's Performance (Regression Metrics) ############\n",
    "\n",
    "\n",
    "# Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "y_true = [3, -0.5, 2]\n",
    "mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# R2 Score\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############# Evaluate Your Model's Performance (Clustering Metrics) ############\n",
    "\n",
    "\n",
    "# Adjusted Rand Index\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "adjusted_rand_score(y_true, y_pred)\n",
    "\n",
    "# Homogeneity\n",
    "from sklearn.metrics import homogeneity_score\n",
    "homogeneity_score(y_true, y_pred)\n",
    "\n",
    "# V-measure\n",
    "from sklearn.metrics import v_measure_score\n",
    "metrics.v_measure_score(y_true, y_pred)\n",
    "\n",
    "# Cross-Validation\n",
    "print(cross_val_score(knn, X_train, y_train, cv=4))\n",
    "print(cross_val_score(lr, X, y, cv=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Tune Your Model ############\n",
    "\n",
    "\n",
    "# Grid Search\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "params = {\"n_neighbors\": np.arange(1,3), \"metric\": [\"euclidean\", \"cityblock\"]}\n",
    "grid = GridSearchCV(estimator=knn,param_grid=params)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.n_neighbors)\n",
    "\n",
    "# Randomized Parameter Optimization\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "params = {\"n_neighbors\": range(1,5), \"weights\": [\"uniform\", \"distance\"]}\n",
    "rsearch = RandomizedSearchCV(estimator=knn,\n",
    "                               param_distributions=params,\n",
    "                               cv=4,\n",
    "                               n_iter=8,\n",
    "                               random_state=5)\n",
    "rsearch.fit(X_train, y_train)\n",
    "print(rsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Going Further ############\n",
    "# Begin with our scikit-learn tutorial for beginners, in which you'll learn in an easy, step-by-step way \n",
    "# how to explore handwritten digits data, how to create a model for it, how to fit your data to your model \n",
    "# and how to predict target values. In addition, you'll make use of Python's data visualization library matplotlib \n",
    "# to visualize your results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
