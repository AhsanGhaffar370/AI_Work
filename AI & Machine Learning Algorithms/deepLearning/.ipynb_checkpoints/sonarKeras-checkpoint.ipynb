{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.1419</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0531</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>0.2120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0477</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.0678</td>\n",
       "      <td>0.1664</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>0.1078</td>\n",
       "      <td>0.1552</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.0599</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.1767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109  \\\n",
       "196  0.0366  0.0421  0.0504  0.0250  0.0596  0.0252  0.0958  0.0991  0.1419   \n",
       "13   0.0124  0.0433  0.0604  0.0449  0.0597  0.0355  0.0531  0.0343  0.1052   \n",
       "32   0.0442  0.0477  0.0049  0.0581  0.0278  0.0678  0.1664  0.1490  0.0974   \n",
       "120  0.0162  0.0041  0.0239  0.0441  0.0630  0.0921  0.1368  0.1078  0.1552   \n",
       "112  0.0283  0.0599  0.0656  0.0229  0.0839  0.1673  0.1154  0.1098  0.1370   \n",
       "\n",
       "     0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  \\\n",
       "196  0.1847  ...  0.0132  0.0027  0.0022  0.0059  0.0016  0.0025  0.0017   \n",
       "13   0.2120  ...  0.0083  0.0057  0.0174  0.0188  0.0054  0.0114  0.0196   \n",
       "32   0.1268  ...  0.0204  0.0216  0.0135  0.0055  0.0073  0.0080  0.0105   \n",
       "120  0.1779  ...  0.0173  0.0135  0.0114  0.0062  0.0157  0.0088  0.0036   \n",
       "112  0.1767  ...  0.0147  0.0170  0.0158  0.0046  0.0073  0.0054  0.0033   \n",
       "\n",
       "     0.0090  0.0032  R  \n",
       "196  0.0027  0.0027  M  \n",
       "13   0.0147  0.0062  R  \n",
       "32   0.0059  0.0105  R  \n",
       "120  0.0053  0.0030  M  \n",
       "112  0.0045  0.0079  M  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sklearn.preprocessing as pp\n",
    "\n",
    "# step01 --> select a data set for training and testing\n",
    "# data_set=pd.read_csv(\"C:\\\\Users\\\\Ahsan Ghaffar\\\\Desktop\\\\Git_AI_Work\\\\AI & Machine Learning Algorithms\\\\data anaysis\\\\sonar.csv\", header=None)\n",
    "data_set=pd.read_csv(\"C:\\\\Users\\\\HP\\\\Desktop\\\\Git_AI_Work\\\\AI & Machine Learning Algorithms\\\\data anaysis\\\\sonar.csv\")\n",
    "\n",
    "data_set=data_set.sample(frac=1)\n",
    "data_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.1419</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0531</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>0.2120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0477</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.0678</td>\n",
       "      <td>0.1664</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>0.1078</td>\n",
       "      <td>0.1552</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.0599</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.1767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109  \\\n",
       "196  0.0366  0.0421  0.0504  0.0250  0.0596  0.0252  0.0958  0.0991  0.1419   \n",
       "13   0.0124  0.0433  0.0604  0.0449  0.0597  0.0355  0.0531  0.0343  0.1052   \n",
       "32   0.0442  0.0477  0.0049  0.0581  0.0278  0.0678  0.1664  0.1490  0.0974   \n",
       "120  0.0162  0.0041  0.0239  0.0441  0.0630  0.0921  0.1368  0.1078  0.1552   \n",
       "112  0.0283  0.0599  0.0656  0.0229  0.0839  0.1673  0.1154  0.1098  0.1370   \n",
       "\n",
       "     0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  \\\n",
       "196  0.1847  ...  0.0132  0.0027  0.0022  0.0059  0.0016  0.0025  0.0017   \n",
       "13   0.2120  ...  0.0083  0.0057  0.0174  0.0188  0.0054  0.0114  0.0196   \n",
       "32   0.1268  ...  0.0204  0.0216  0.0135  0.0055  0.0073  0.0080  0.0105   \n",
       "120  0.1779  ...  0.0173  0.0135  0.0114  0.0062  0.0157  0.0088  0.0036   \n",
       "112  0.1767  ...  0.0147  0.0170  0.0158  0.0046  0.0073  0.0054  0.0033   \n",
       "\n",
       "     0.0090  0.0032  R  \n",
       "196  0.0027  0.0027  0  \n",
       "13   0.0147  0.0062  1  \n",
       "32   0.0059  0.0105  1  \n",
       "120  0.0053  0.0030  0  \n",
       "112  0.0045  0.0079  0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_enc = pp.LabelEncoder().fit(data_set['R'])\n",
    "data_set['R']= r_enc.transform(data_set['R'])\n",
    "\n",
    "# train_df = train_df.replace(['Setosa', 'Virginica', 'Versicolor'], [0,1,2])\n",
    "\n",
    "data_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['0', '1']) remove row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_set.values[:, :-1]  #x\n",
    "labels= data_set.values[: , -1]  # y\n",
    "\n",
    "\n",
    "train=70\n",
    "index=int(len(data_set)*int(train)/100) #find last index num for 70% training data\n",
    "\n",
    "index1=int(len(data_set)*int(20)/100) ## find 20% for validation\n",
    "index1=index+index1\n",
    "\n",
    "\n",
    "\n",
    "feature_train=features[0:index,:]\n",
    "label_train=labels[0:index]\n",
    "\n",
    "validation_train=features[index:index1,:]\n",
    "validation_test=labels[index:index1]\n",
    "\n",
    "feature_test=features[index1:len(data_set),:]\n",
    "label_test=labels[index1:len(data_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train=data_set[data_set.columns[:-1]]\n",
    "# y_test=data_set[data_set.columns[-1]]\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_train, y_test ,test_size = 0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(60,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144 samples, validate on 41 samples\n",
      "Epoch 1/60\n",
      "144/144 [==============================] - 0s 3ms/sample - loss: 0.5176 - acc: 0.7500 - val_loss: 0.6690 - val_acc: 0.5366\n",
      "Epoch 2/60\n",
      "144/144 [==============================] - 0s 62us/sample - loss: 0.5119 - acc: 0.7292 - val_loss: 0.6641 - val_acc: 0.5122\n",
      "Epoch 3/60\n",
      "144/144 [==============================] - 0s 72us/sample - loss: 0.5083 - acc: 0.7639 - val_loss: 0.6623 - val_acc: 0.5366\n",
      "Epoch 4/60\n",
      "144/144 [==============================] - 0s 69us/sample - loss: 0.5041 - acc: 0.7292 - val_loss: 0.6582 - val_acc: 0.5366\n",
      "Epoch 5/60\n",
      "144/144 [==============================] - 0s 83us/sample - loss: 0.4999 - acc: 0.7778 - val_loss: 0.6550 - val_acc: 0.5610\n",
      "Epoch 6/60\n",
      "144/144 [==============================] - 0s 69us/sample - loss: 0.4966 - acc: 0.7500 - val_loss: 0.6521 - val_acc: 0.5366\n",
      "Epoch 7/60\n",
      "144/144 [==============================] - 0s 76us/sample - loss: 0.4934 - acc: 0.7778 - val_loss: 0.6492 - val_acc: 0.5610\n",
      "Epoch 8/60\n",
      "144/144 [==============================] - 0s 83us/sample - loss: 0.4906 - acc: 0.7569 - val_loss: 0.6464 - val_acc: 0.5610\n",
      "Epoch 9/60\n",
      "144/144 [==============================] - 0s 76us/sample - loss: 0.4878 - acc: 0.7917 - val_loss: 0.6433 - val_acc: 0.5610\n",
      "Epoch 10/60\n",
      "144/144 [==============================] - 0s 76us/sample - loss: 0.4851 - acc: 0.7708 - val_loss: 0.6409 - val_acc: 0.5610\n",
      "Epoch 11/60\n",
      "144/144 [==============================] - 0s 83us/sample - loss: 0.4825 - acc: 0.7847 - val_loss: 0.6382 - val_acc: 0.5610\n",
      "Epoch 12/60\n",
      "144/144 [==============================] - 0s 90us/sample - loss: 0.4799 - acc: 0.7847 - val_loss: 0.6356 - val_acc: 0.5610\n",
      "Epoch 13/60\n",
      "144/144 [==============================] - 0s 76us/sample - loss: 0.4775 - acc: 0.7917 - val_loss: 0.6331 - val_acc: 0.5610\n",
      "Epoch 14/60\n",
      "144/144 [==============================] - 0s 69us/sample - loss: 0.4750 - acc: 0.7847 - val_loss: 0.6293 - val_acc: 0.5610\n",
      "Epoch 15/60\n",
      "144/144 [==============================] - 0s 69us/sample - loss: 0.4726 - acc: 0.7986 - val_loss: 0.6295 - val_acc: 0.5610\n",
      "Epoch 16/60\n",
      "144/144 [==============================] - 0s 69us/sample - loss: 0.4705 - acc: 0.7986 - val_loss: 0.6242 - val_acc: 0.5610\n",
      "Epoch 17/60\n",
      "144/144 [==============================] - 0s 90us/sample - loss: 0.4685 - acc: 0.8056 - val_loss: 0.6256 - val_acc: 0.5366\n",
      "Epoch 18/60\n",
      "144/144 [==============================] - 0s 97us/sample - loss: 0.4663 - acc: 0.7917 - val_loss: 0.6187 - val_acc: 0.5610\n",
      "Epoch 19/60\n",
      "144/144 [==============================] - 0s 104us/sample - loss: 0.4641 - acc: 0.8125 - val_loss: 0.6211 - val_acc: 0.5366\n",
      "Epoch 20/60\n",
      "144/144 [==============================] - 0s 104us/sample - loss: 0.4619 - acc: 0.8056 - val_loss: 0.6141 - val_acc: 0.5610\n",
      "Epoch 21/60\n",
      "144/144 [==============================] - 0s 97us/sample - loss: 0.4596 - acc: 0.8056 - val_loss: 0.6151 - val_acc: 0.5610\n",
      "Epoch 22/60\n",
      "144/144 [==============================] - 0s 97us/sample - loss: 0.4575 - acc: 0.8056 - val_loss: 0.6098 - val_acc: 0.5610\n",
      "Epoch 23/60\n",
      "144/144 [==============================] - 0s 118us/sample - loss: 0.4553 - acc: 0.7986 - val_loss: 0.6112 - val_acc: 0.5610\n",
      "Epoch 24/60\n",
      "144/144 [==============================] - 0s 90us/sample - loss: 0.4533 - acc: 0.8056 - val_loss: 0.6055 - val_acc: 0.5854\n",
      "Epoch 25/60\n",
      "144/144 [==============================] - 0s 69us/sample - loss: 0.4512 - acc: 0.8125 - val_loss: 0.6072 - val_acc: 0.5610\n",
      "Epoch 26/60\n",
      "144/144 [==============================] - 0s 69us/sample - loss: 0.4493 - acc: 0.8056 - val_loss: 0.6005 - val_acc: 0.6098\n",
      "Epoch 27/60\n",
      "144/144 [==============================] - 0s 90us/sample - loss: 0.4473 - acc: 0.8333 - val_loss: 0.6042 - val_acc: 0.5610\n",
      "Epoch 28/60\n",
      "144/144 [==============================] - 0s 76us/sample - loss: 0.4454 - acc: 0.8056 - val_loss: 0.5968 - val_acc: 0.6341\n",
      "Epoch 29/60\n",
      "144/144 [==============================] - 0s 83us/sample - loss: 0.4434 - acc: 0.8333 - val_loss: 0.5996 - val_acc: 0.5610\n",
      "Epoch 30/60\n",
      "144/144 [==============================] - 0s 90us/sample - loss: 0.4414 - acc: 0.8056 - val_loss: 0.5927 - val_acc: 0.6341\n",
      "Epoch 31/60\n",
      "144/144 [==============================] - 0s 90us/sample - loss: 0.4395 - acc: 0.8333 - val_loss: 0.5961 - val_acc: 0.5610\n",
      "Epoch 32/60\n",
      "144/144 [==============================] - 0s 90us/sample - loss: 0.4376 - acc: 0.8125 - val_loss: 0.5887 - val_acc: 0.6341\n",
      "Epoch 33/60\n",
      "144/144 [==============================] - 0s 83us/sample - loss: 0.4357 - acc: 0.8333 - val_loss: 0.5926 - val_acc: 0.5854\n",
      "Epoch 34/60\n",
      "144/144 [==============================] - 0s 90us/sample - loss: 0.4339 - acc: 0.8125 - val_loss: 0.5851 - val_acc: 0.6341\n",
      "Epoch 35/60\n",
      "144/144 [==============================] - 0s 90us/sample - loss: 0.4319 - acc: 0.8333 - val_loss: 0.5895 - val_acc: 0.6098\n",
      "Epoch 36/60\n",
      "144/144 [==============================] - 0s 76us/sample - loss: 0.4302 - acc: 0.8125 - val_loss: 0.5813 - val_acc: 0.6341\n",
      "Epoch 37/60\n",
      "144/144 [==============================] - 0s 90us/sample - loss: 0.4283 - acc: 0.8403 - val_loss: 0.5861 - val_acc: 0.6341\n",
      "Epoch 38/60\n",
      "144/144 [==============================] - 0s 97us/sample - loss: 0.4265 - acc: 0.8125 - val_loss: 0.5778 - val_acc: 0.6341\n",
      "Epoch 39/60\n",
      "144/144 [==============================] - 0s 83us/sample - loss: 0.4245 - acc: 0.8403 - val_loss: 0.5823 - val_acc: 0.6585\n",
      "Epoch 40/60\n",
      "144/144 [==============================] - 0s 76us/sample - loss: 0.4228 - acc: 0.8125 - val_loss: 0.5743 - val_acc: 0.6341\n",
      "Epoch 41/60\n",
      "144/144 [==============================] - 0s 76us/sample - loss: 0.4209 - acc: 0.8403 - val_loss: 0.5801 - val_acc: 0.6829\n",
      "Epoch 42/60\n",
      "144/144 [==============================] - 0s 97us/sample - loss: 0.4193 - acc: 0.8125 - val_loss: 0.5710 - val_acc: 0.6585\n",
      "Epoch 43/60\n",
      "144/144 [==============================] - 0s 97us/sample - loss: 0.4176 - acc: 0.8472 - val_loss: 0.5782 - val_acc: 0.6829\n",
      "Epoch 44/60\n",
      "144/144 [==============================] - 0s 90us/sample - loss: 0.4162 - acc: 0.8056 - val_loss: 0.5678 - val_acc: 0.6585\n",
      "Epoch 45/60\n",
      "144/144 [==============================] - 0s 69us/sample - loss: 0.4144 - acc: 0.8611 - val_loss: 0.5757 - val_acc: 0.6829\n",
      "Epoch 46/60\n",
      "144/144 [==============================] - 0s 97us/sample - loss: 0.4128 - acc: 0.8056 - val_loss: 0.5653 - val_acc: 0.6585\n",
      "Epoch 47/60\n",
      "144/144 [==============================] - 0s 83us/sample - loss: 0.4109 - acc: 0.8611 - val_loss: 0.5722 - val_acc: 0.6829\n",
      "Epoch 48/60\n",
      "144/144 [==============================] - 0s 90us/sample - loss: 0.4092 - acc: 0.8125 - val_loss: 0.5633 - val_acc: 0.6585\n",
      "Epoch 49/60\n",
      "144/144 [==============================] - 0s 69us/sample - loss: 0.4073 - acc: 0.8472 - val_loss: 0.5693 - val_acc: 0.6829\n",
      "Epoch 50/60\n",
      "144/144 [==============================] - 0s 76us/sample - loss: 0.4058 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.6585\n",
      "Epoch 51/60\n",
      "144/144 [==============================] - 0s 83us/sample - loss: 0.4041 - acc: 0.8542 - val_loss: 0.5664 - val_acc: 0.6829\n",
      "Epoch 52/60\n",
      "144/144 [==============================] - 0s 132us/sample - loss: 0.4025 - acc: 0.8194 - val_loss: 0.5582 - val_acc: 0.6585\n",
      "Epoch 53/60\n",
      "144/144 [==============================] - 0s 76us/sample - loss: 0.4008 - acc: 0.8542 - val_loss: 0.5645 - val_acc: 0.7073\n",
      "Epoch 54/60\n",
      "144/144 [==============================] - 0s 125us/sample - loss: 0.3994 - acc: 0.8194 - val_loss: 0.5554 - val_acc: 0.6829\n",
      "Epoch 55/60\n",
      "144/144 [==============================] - 0s 118us/sample - loss: 0.3978 - acc: 0.8681 - val_loss: 0.5638 - val_acc: 0.7073\n",
      "Epoch 56/60\n",
      "144/144 [==============================] - 0s 104us/sample - loss: 0.3964 - acc: 0.8125 - val_loss: 0.5535 - val_acc: 0.6829\n",
      "Epoch 57/60\n",
      "144/144 [==============================] - 0s 76us/sample - loss: 0.3949 - acc: 0.8681 - val_loss: 0.5622 - val_acc: 0.7073\n",
      "Epoch 58/60\n",
      "144/144 [==============================] - 0s 69us/sample - loss: 0.3935 - acc: 0.8125 - val_loss: 0.5509 - val_acc: 0.6829\n",
      "Epoch 59/60\n",
      "144/144 [==============================] - 0s 139us/sample - loss: 0.3918 - acc: 0.8681 - val_loss: 0.5600 - val_acc: 0.7073\n",
      "Epoch 60/60\n",
      "144/144 [==============================] - 0s 111us/sample - loss: 0.3904 - acc: 0.8194 - val_loss: 0.5492 - val_acc: 0.6829\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "# history = model.fit(feature_train, label_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))\n",
    "history = model.fit(feature_train, label_train, epochs=60, batch_size=index, validation_data=(validation_train, validation_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 182us/sample - loss: 0.4350 - acc: 0.7273\n",
      "loss 43.503206968307495\n",
      "Accuracy 72.72727489471436\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(feature_test,label_test)\n",
    "print(\"loss\",evaluate[0]*100)\n",
    "print(\"Accuracy\",evaluate[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 62us/sample - loss: 0.3886 - acc: 0.8681\n",
      "loss 38.86408077345954\n",
      "Accuracy 86.80555820465088\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(feature_train,label_train)\n",
    "print(\"loss\",evaluate[0]*100)\n",
    "print(\"Accuracy\",evaluate[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
